{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pydataset.data(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.layers import Dropout\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.python.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.backend import sigmoid\n",
    "from matplotlib import cm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
       "1           5.1          3.5           1.4          0.2  setosa\n",
       "2           4.9          3.0           1.4          0.2  setosa\n",
       "3           4.7          3.2           1.3          0.2  setosa\n",
       "4           4.6          3.1           1.5          0.2  setosa\n",
       "5           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "labels = le.fit_transform(df['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width  Species\n",
       "1           5.1          3.5           1.4          0.2        0\n",
       "2           4.9          3.0           1.4          0.2        0\n",
       "3           4.7          3.2           1.3          0.2        0\n",
       "4           4.6          3.1           1.5          0.2        0\n",
       "5           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Species'] = labels\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"Sepal.Length\", \"Sepal.Width\", \"Petal.Length\", \"Petal.Width\"]]\n",
    "y = df[['Species']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2)\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df['Petal.Width'], df['Species'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnModel = KNeighborsClassifier(n_neighbors=3)\n",
    "knnModel.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnModel.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.RELU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "#CREATING THE ANN AS SEQUENCE OF LAYERS\n",
    "ann = Sequential()\n",
    "\n",
    "#ADD FIRST HIDDEN LAYER WITH 30 NEURONS, THE INPUT LAYERS WILL BE ADDED AUTOAMTICALLY,\n",
    "ann.add(Dense(units = 30,activation = 'relu'))\n",
    "ann.add(BatchNormalization())\n",
    "ann.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "#ADDING OUTPUT LAYER WITH 1 NEURON, AS THIS IS BINARY CLASSIFICATION\n",
    "ann.add(Dense(units = 1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 166ms/step\n"
     ]
    }
   ],
   "source": [
    "#now testing for Test data \n",
    "y_pred = ann.predict(x_test)\n",
    "#converting values\n",
    "y_pred = (y_pred>0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  8  0]\n",
      " [ 0 11  0]\n",
      " [ 2  9  0]]\n",
      "score is 0.36666666666666664\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "score1 = accuracy_score(y_test,y_pred)\n",
    "print(cm)\n",
    "print(\"score is\",score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.39      1.00      0.56        11\n",
      "           2       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.37        30\n",
      "   macro avg       0.13      0.33      0.19        30\n",
      "weighted avg       0.14      0.37      0.21        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/wAAAJGCAYAAADmh45cAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAn40lEQVR4nO3de5SWdbk38Gs4jUQ4WxwYwENS29LEM4SEh0iW6PKEey3Ntu5NuLdtdURxKpV3p+gyG9NSMk87K9GVuM23NK22bcMU2agIpGYe8PSWWczItkARh8Nzv3+0Xt49ieDI8NzD9Xw+rvsPfs/Mc1+zVmt6rvn+rt9dVxRFEQAAAEAqvcouAAAAAOh+Gn4AAABISMMPAAAACWn4AQAAICENPwAAACSk4QcAAICENPwAAACQkIYfAAAAEupTdgH/T59+O5RdAlDDlp9/UNklADWs4bKHyi4BqHFrV79adglbxJplL1XtXn0bP1y1e71XEn4AAABIqMck/AAAANCtKuvKrqBUEn4AAABISMIPAABATkWl7ApKJeEHAACAhDT8AAAAkJAt/QAAAORUsaUfAAAASEbCDwAAQEqFQ/sAAACAbCT8AAAA5GSGHwAAAMhGwg8AAEBOZvgBAACAbCT8AAAA5FRZV3YFpZLwAwAAQEISfgAAAHIyww8AAABkI+EHAAAgp4qEHwAAAEhGwg8AAEBKhRl+AAAAIBsJPwAAADmZ4QcAAACy0fADAABAQrb0AwAAkJND+wAAAIBsJPwAAADkVFlXdgWlkvADAABAQhJ+AAAAcjLDDwAAAGQj4QcAACCnioQfAAAASEbCDwAAQE5m+AEAAIBsJPwAAADkZIYfAAAAyEbCDwAAQEpFsa7sEkol4QcAAICEJPwAAADk5JR+AAAAIBsJPwAAADk5pR8AAADIRsIPAABATmb4AQAAgGqZO3duHH300TF8+PCoq6uLu+66q9PrRVHEhRdeGMOGDYv+/fvHhAkT4vnnn+/yfTT8AAAAUEUrV66MvffeO6699toNvn755ZfH1VdfHTfccEM8+uijMWDAgJg4cWK8/fbbXbqPLf0AAADkVFlXdgUbdMQRR8QRRxyxwdeKooiZM2fGl7/85Tj22GMjIuKWW26JpqamuOuuu+LEE098z/eR8AMAAMBm6ujoiBUrVnS6Ojo6uvw+L7/8cixdujQmTJiwfq2hoSHGjBkTDz/8cJfeS8MPAABATkWlaldra2s0NDR0ulpbW7tc8tKlSyMioqmpqdN6U1PT+tfeK1v6AQAAYDNNnz49WlpaOq3V19eXVM1faPgBAADIqVK9x/LV19d3S4M/dOjQiIhoa2uLYcOGrV9va2uLffbZp0vvZUs/AAAA9BAjRoyIoUOHxpw5c9avrVixIh599NEYO3Zsl95Lwg8AAEBORfUS/q54880344UXXlj/75dffjkef/zxGDRoUOy8884xbdq0+MpXvhK77rprjBgxIi644IIYPnx4TJo0qUv30fADAABAFS1cuDDGjx+//t//b/Z/8uTJMWvWrDj33HNj5cqV8fnPfz7+/Oc/x4EHHhj33ntvbLPNNl26T11RFEW3Vv4+9em3Q9klADVs+fkHlV0CUMMaLnuo7BKAGrd29atll7BFvP1ft1btXtuMO6lq93qvzPADAABAQrb0AwAAkFMVT+nviST8AAAAkJCEHwAAgJSKYl3ZJZRKwg8AAAAJSfgBAADIyQw/AAAAkI2EHwAAgJwKCT8AAACQjIYfAAAAErKlHwAAgJwc2gcAAABkI+EHAAAgJ4f2AQAAANlI+AEAAMjJDD8AAACQjYQfAACAnMzwAwAAANlI+AEAAMjJDD8AAACQjYQfAACAnCT8AAAAQDYSfgAAAHJySj8AAACQjYQfAACAnMzwAwAAANlI+AEAAMjJDD8AAACQjYQfAACAnMzww9bt9NMmxwtLHok3V7wY8+fdE6NH7VN2SUAtqKuLvp8+Ifqfc3V84IJbov+0b0bfQ/6u7KqAGuSzEPBuNPxs1Y4//pj4+hUz4pKvXBmjxxweTzz5dPzsp7fG4MHbl10akFzfg46NvqMnxOqf3hSrvvWFWP2fs6PvgUdHnzGHl10aUEN8FgI2RsPPVu2cs0+N73x3dtx8yw/imWeejzOaz4+33loVUz53YtmlAcn12umjsfbZRbFuya+i+PNrse7pR2PdC09G7x0/UnZpQA3xWQg2oahU7+qButzwL1u2LC6//PI47rjjYuzYsTF27Ng47rjj4oorrojXXnttS9QIG9S3b9/Yb7+9Ys79D61fK4oi5tw/Lw44YP8SKwNqQeWVJdH7wyOjbvthERHRq2nn6P2hj8Xa5x8vtzCgZvgsBGxKlw7te+yxx2LixInxgQ98ICZMmBAf/ehHIyKira0trr766rjsssvi5z//eYwaNWqj79PR0REdHR2d1oqiiLq6ui6WTy1rbBwUffr0ifa2ZZ3W29tfi90+JmEDtqw1D/04or5/9J/6jb/8Vb+uV6yZc3use/K/yi4NqBE+C8F7UOOH9nWp4Z86dWocf/zxccMNN7yjOS+KIk477bSYOnVqPPzwwxt9n9bW1rj44os7rdX1+mDU9d62K+UAQGl673FA9NnrwOj439+KSvvvo/ewXaLfEf8YxRt/irWPzy27PACArjX8TzzxRMyaNWuDSXxdXV2cc845se+++27yfaZPnx4tLS2d1rbbfreulAKxbNnrsXbt2hjS1NhpfciQwbG0zXgJsGX1m3hyrHnox7Huqb/8kXtt+ytR9zeN0fegYzX8QFX4LATvQY0n/F2a4R86dGgsWLDgXV9fsGBBNDU1bfJ96uvrY9ttt+102c5PV61ZsyYWL34yPj3+wPVrdXV18enxB8YjjywqsTKgFtT17RdRFJ0XK3/Z2g9QDT4LAZvSpYT/i1/8Ynz+85+PRYsWxaGHHrq+uW9ra4s5c+bEjTfeGF//+te3SKGwIVd988a46btXxaLFT8Zjj/0qzpp6agwY0D9m3Xx72aUBya19bnH0PXhSFMuXRaX999Fr2C7R95NHxprFD5RdGlBDfBaCTfjrP87XmC41/M3NzdHY2BhXXXVVXHfddbFu3bqIiOjdu3fsv//+MWvWrDjhhBO2SKGwIXfccXcMbhwUF134xRg6dHA88cRv4sijTo729mWb/maAzbD6pzdFv0NPiH5HnRJ1AxqieONPsWbhL2LNAz8suzSghvgsBGxMXVG8vz95rFmzJpYt+8svksbGxujbt+9mFdKn3w6b9f0Am2P5+QeVXQJQwxoue2jTXwSwBa1d/WrZJWwRq26bUbV79f/sxZv+oirrUsL/P/Xt2zeGDRvWnbUAAAAA3eR9N/wAAADQozmlHwAAAMhGwg8AAEBOhYQfAAAASEbCDwAAQE5m+AEAAIBsJPwAAADkVBRlV1AqCT8AAAAkpOEHAACAhGzpBwAAICeH9gEAAADZSPgBAADIScIPAAAAZCPhBwAAIKdCwg8AAAAkI+EHAAAgpaJSlF1CqST8AAAAkJCEHwAAgJyc0g8AAABkI+EHAAAgJ6f0AwAAANlI+AEAAMjJKf0AAABANhJ+AAAAcnJKPwAAAJCNhB8AAICcJPwAAABANhp+AAAASMiWfgAAAHIqPJYPAAAASEbCDwAAQE4O7QMAAACykfADAACQU8UMPwAAAJCMhB8AAICcCjP8AAAAQDISfgAAAHIyww8AAABkI+EHAAAgpaJihh8AAABIRsIPAABATmb4AQAAgGwk/AAAAORUmOEHAAAAkpHwAwAAkJMZfgAAACAbDT8AAAA5VSrVu7pg3bp1ccEFF8SIESOif//+8ZGPfCQuueSSKIru3ZFgSz8AAABU0de+9rW4/vrr4+abb4499tgjFi5cGFOmTImGhoY466yzuu0+Gn4AAACoovnz58exxx4bRx55ZERE7LLLLnHbbbfFggULuvU+tvQDAACQU6Wo2tXR0RErVqzodHV0dGywrE9+8pMxZ86cWLJkSUREPPHEEzFv3rw44ogjuvXH1/ADAADAZmptbY2GhoZOV2tr6wa/9vzzz48TTzwxdtttt+jbt2/su+++MW3atDjppJO6tSZb+gEAAMip6Npheptj+vTp0dLS0mmtvr5+g1/7gx/8IG699daYPXt27LHHHvH444/HtGnTYvjw4TF58uRuq0nDDwAAAJupvr7+XRv8v/alL31pfcofEbHnnnvGb3/722htbdXwAwAAwCZVuvcxd93lrbfeil69Ok/Y9+7dOypdfLzfpmj4AQAAoIqOPvrouPTSS2PnnXeOPfbYI371q1/FlVdeGaecckq33kfDDwAAQEpFNyfm3eVb3/pWXHDBBXHGGWdEe3t7DB8+PP7lX/4lLrzwwm69j4YfAAAAqmjgwIExc+bMmDlz5ha9j4YfAACAnHroDH+19Nr0lwAAAABbGwk/AAAAOUn4AQAAgGwk/AAAAORU9MxT+qtFwg8AAAAJSfgBAADIyQw/AAAAkI2EHwAAgJQKCT8AAACQjYYfAAAAErKlHwAAgJxs6QcAAACykfADAACQU6VSdgWlkvADAABAQhJ+AAAAcjLDDwAAAGQj4QcAACAnCT8AAACQjYQfAACAlIpCwg8AAAAkI+EHAAAgJzP8AAAAQDYSfgAAAHKS8AMAAADZSPgBAABIqajxhF/DDxAR/c76atklALXssoPKrgCAhDT8AAAA5FTjCb8ZfgAAAEhIwg8AAEBOlbILKJeEHwAAABLS8AMAAEBCtvQDAACQUq0/lk/CDwAAAAlJ+AEAAMhJwg8AAABkI+EHAAAgJ4/lAwAAALKR8AMAAJCSU/oBAACAdCT8AAAA5GSGHwAAAMhGwg8AAEBKZvgBAACAdCT8AAAA5GSGHwAAAMhGwg8AAEBKhYQfAAAAyEbCDwAAQE4SfgAAACAbDT8AAAAkZEs/AAAAKTm0DwAAAEhHwg8AAEBOEn4AAAAgGwk/AAAAKZnhBwAAANKR8AMAAJCShB8AAABIR8IPAABAShJ+AAAAIB0JPwAAADkVdWVXUCoJPwAAACQk4QcAACAlM/wAAABAOhJ+AAAAUioqZvgBAACAZCT8AAAApGSGHwAAAEhHwg8AAEBKRWGGHwAAAEhGww8AAAAJ2dIPAABASg7tAwAAANKR8AMAAJBSUXFoHwAAAJCMhB8AAICUiqLsCsol4QcAAICEJPwAAACkZIYfAAAASEfCDwAAQEoSfgAAACAdCT8AAAApOaUfAAAASEfCDwAAQEpm+AEAAIB0JPwAAACkVBQSfgAAAKCKXn311Tj55JNj++23j/79+8eee+4ZCxcu7NZ7SPgBAABIqaiUXcGG/elPf4px48bF+PHj4z/+4z9i8ODB8fzzz8d2223XrffR8AMAAEAVfe1rX4uddtopbrrppvVrI0aM6Pb72NIPAAAAm6mjoyNWrFjR6ero6Njg1959990xatSoOP7442PIkCGx7777xo033tjtNWn4AQAASKlS1FXtam1tjYaGhk5Xa2vrBut66aWX4vrrr49dd901fv7zn8fpp58eZ511Vtx8883d+vPXFUVRdOs7vk99+u1QdglADVv1h4fKLgGoYf2HH1R2CUCNW7v61bJL2CKW7H541e71ocd//I5Ev76+Purr69/xtf369YtRo0bF/Pnz16+dddZZ8dhjj8XDDz/cbTWZ4QcAACClaj6W792a+w0ZNmxYfPzjH++0tvvuu8cPf/jDbq3Jln4AAACoonHjxsVzzz3XaW3JkiXxoQ99qFvvI+EHAAAgpaJSvYS/K84555z45Cc/GV/96lfjhBNOiAULFsS3v/3t+Pa3v92t95HwAwAAQBWNHj067rzzzrjtttti5MiRcckll8TMmTPjpJNO6tb7SPgBAABIqWccUb9hRx11VBx11FFb9B4SfgAAAEhIwg8AAEBKPXWGv1ok/AAAAJCQhB8AAICUKoWEHwAAAEhGwg8AAEBKhYQfAAAAyEbCDwAAQEpFUXYF5ZLwAwAAQEISfgAAAFJySj8AAACQjoQfAACAlJzSDwAAAKSj4Werd/ppk+OFJY/EmytejPnz7onRo/YpuyQgoYWP/zqaz50R4485KUaOOyLmzJ3f6fX7HvivOHXa/4pxR5wQI8cdEc8uebGkSoFa47MQ8G40/GzVjj/+mPj6FTPikq9cGaPHHB5PPPl0/Oynt8bgwduXXRqQzKpVb8fH/vbD8a9fOGPDr7/9duy31x5xzumnVLkyoJb5LAQbVxTVu3oiDT9btXPOPjW+893ZcfMtP4hnnnk+zmg+P956a1VM+dyJZZcGJHPQ2NFx1ucnx4RDxm3w9WMOPzROP+WkGDt63ypXBtQyn4WAjdHws9Xq27dv7LffXjHn/ofWrxVFEXPunxcHHLB/iZUBAGx5PgvBplWKuqpdPVG3N/yvvPJKnHLKxrczdnR0xIoVKzpdRU/dA0GP1dg4KPr06RPtbcs6rbe3vxZDmwaXVBUAQHX4LARsSrc3/K+//nrcfPPNG/2a1tbWaGho6HQVlTe6uxQAAABqWFHUVe3qifp09Rvuvvvujb7+0ksvbfI9pk+fHi0tLZ3Wttt+t66WQo1btuz1WLt2bQxpauy0PmTI4Fja9lpJVQEAVIfPQsCmdLnhnzRpUtTV1W10C35d3cb/ulFfXx/19fVd+h74a2vWrInFi5+MT48/MO6+++cR8Zf/HX16/IFx3fU3lVwdAMCW5bMQbFpPna2vli5v6R82bFj86Ec/ikqlssFr8eLFW6JO2KCrvnlj/PM//X38wz8cH7vt9rdx7TWXxYAB/WPWzbeXXRqQzFtvrYpnl7wYzy55MSIiXv1DWzy75MX449L2iIhYvuKNeHbJi/Hiy7+NiIiXf/f7eHbJi7Hsv18vrWYgP5+FgI3pcsK///77x6JFi+LYY4/d4OubSv+hO91xx90xuHFQXHThF2Po0MHxxBO/iSOPOjna25dt+psBuuCpZ5+PU6aet/7fl3/r2xERcewRE+LSL38hfvnQI/Hlr165/vUvzbgsIiJOP+WkaP6nk6tbLFAzfBaCjav1zrSu6GJ3/tBDD8XKlSvj8MMP3+DrK1eujIULF8YhhxzSpUL69NuhS18P0J1W/eGhTX8RwBbSf/hBZZcA1Li1q18tu4Qt4pHhf1e1ex3whx9V7V7vVZcT/oMO2vj/IQ0YMKDLzT4AAAB0NzP8AAAAQDpdTvgBAABga1BI+AEAAIBsJPwAAACkVCm7gJJJ+AEAACAhCT8AAAApFWGGHwAAAEhGww8AAAAJ2dIPAABASpWi7ArKJeEHAACAhCT8AAAApFRxaB8AAACQjYQfAACAlDyWDwAAAEhHwg8AAEBKlbILKJmEHwAAABKS8AMAAJCSGX4AAAAgHQk/AAAAKZnhBwAAANKR8AMAAJCShB8AAABIR8IPAABASk7pBwAAANKR8AMAAJBSpbYDfgk/AAAAZCThBwAAIKWKGX4AAAAgGw0/AAAAJGRLPwAAACkVZRdQMgk/AAAAJCThBwAAIKVK2QWUTMIPAAAACUn4AQAASKlS57F8AAAAQDISfgAAAFJySj8AAACQjoQfAACAlJzSDwAAAKQj4QcAACClSm0f0i/hBwAAgIwk/AAAAKRUidqO+CX8AAAAkJCEHwAAgJSKsgsomYQfAAAAEpLwAwAAkJJT+gEAAIB0NPwAAACQkC39AAAApFQpu4CSSfgBAAAgIQk/AAAAKXksHwAAAJCOhB8AAICUPJYPAAAASEfCDwAAQEpO6QcAAADSkfADAACQkoQfAAAASEfCDwAAQEqFU/oBAACAbCT8AAAApGSGHwAAAEhHww8AAEBKlSpe79dll10WdXV1MW3atM14lw3T8AMAAEAJHnvssfi3f/u32GuvvbbI+2v4AQAASKmo4tVVb775Zpx00klx4403xnbbbfc+f8KN0/ADAADAZuro6IgVK1Z0ujo6Ot7165ubm+PII4+MCRMmbLGaNPwAAACkVKmr3tXa2hoNDQ2drtbW1g3W9e///u+xePHid329u3gsHwAAAGym6dOnR0tLS6e1+vr6d3zdK6+8EmeffXbcd999sc0222zRmjT8AAAAsJnq6+s32OD/tUWLFkV7e3vst99+69fWrVsXc+fOjWuuuSY6Ojqid+/e3VKThh8AAICUNudxeVvKoYceGr/+9a87rU2ZMiV22223OO+887qt2Y/Q8AMAAEDVDBw4MEaOHNlpbcCAAbH99tu/Y31zafgBAABIqScm/NWk4QcAAIASPfDAA1vkfTX8AAAApFSUXUDJepVdAAAAAND9JPwAAACkVKkru4JySfgBAAAgIQk/AAAAKdX6Kf0SfgAAAEhIwg8AAEBKTukHAAAA0pHwAwAAkFKlxjN+CT8AAAAk1GMS/k837Vl2CUANW/vzm8ouAQCAbuaUfgAAACCdHpPwAwAAQHeq7Ql+CT8AAACkpOEHAACAhGzpBwAAICWH9gEAAADpSPgBAABIqVJXdgXlkvADAABAQhJ+AAAAUqrU+IP5JPwAAACQkIQfAACAlGo735fwAwAAQEoSfgAAAFKqlF1AyST8AAAAkJCEHwAAgJSc0g8AAACkI+EHAAAgpdrO9yX8AAAAkJKEHwAAgJSc0g8AAACkI+EHAAAgJaf0AwAAAOlI+AEAAEiptvN9CT8AAACkpOEHAACAhGzpBwAAICWP5QMAAADSkfADAACQUlHjx/ZJ+AEAACAhCT8AAAApmeEHAAAA0pHwAwAAkFLFDD8AAACQjYQfAACAlGo735fwAwAAQEoSfgAAAFIyww8AAACkI+EHAAAgpUrZBZRMwg8AAAAJSfgBAABIqTDDDwAAAGQj4QcAACAlM/wAAABAOhp+AAAASMiWfgAAAFJyaB8AAACQjoQfAACAlBzaBwAAAKQj4QcAACClSmGGHwAAAEhGwg8AAEBKtZ3vS/gBAAAgJQk/AAAAKVVqPOOX8AMAAEBCEn4AAABSKiT8AAAAQDYSfgAAAFKqlF1AyST8AAAAkJCEHwAAgJSc0g8AAACkI+EHAAAgJaf0AwAAAOlI+AEAAEjJKf0AAABAOhp+AAAASMiWfgAAAFIqCof2AQAAAMlI+AEAAEip4rF8AAAAQDYSfgAAAFLyWD4AAAAgHQk/AAAAKRVm+AEAAIBsJPwAAACk5JR+AAAAIB0JPwAAACkVhYQfAAAAqJLW1tYYPXp0DBw4MIYMGRKTJk2K5557rtvvo+EHAAAgpUoVr6548MEHo7m5OR555JG47777Ys2aNXHYYYfFypUrN+OnfSdb+gEAAKCK7r333k7/njVrVgwZMiQWLVoUBx98cLfdR8MPAABASkUVT+nv6OiIjo6OTmv19fVRX1+/ye9dvnx5REQMGjSoW2uypR8AAAA2U2trazQ0NHS6WltbN/l9lUolpk2bFuPGjYuRI0d2a00SfgAAAFKqVDHhnz59erS0tHRaey/pfnNzczz11FMxb968bq9Jww8AAACb6b1u3/+fzjzzzPjJT34Sc+fOjR133LHba9Lws9U6sfkzMe6IcbHTR3aM1W+vjqcXPR3f+er34vcv/b7s0oAasbJjTVz7wFPxy2dfjddXdsTHhv5NnDtx3xi5Q/fO3wFszOmnTY4vtJweQ4cOjieffDrOnnZBPLbw8bLLAjaiKIqYOnVq3HnnnfHAAw/EiBEjtsh9zPCz1drzgD3j7pvvibOPPSfO//vp0btPn2i99dLYpn/X/qoG8H5dfM/CeOSltvjKpDFxx2mHxdgPN8Vp338w2la8VXZpQI04/vhj4utXzIhLvnJljB5zeDzx5NPxs5/eGoMHb192adAjFEVRtasrmpub4/vf/37Mnj07Bg4cGEuXLo2lS5fGqlWruvXn1/Cz1frXf/hy3HfHffHbJb+Nl555Ob7e8o1o2rEpdt1r17JLA2rA22vWxpxnfh/TDt0r9v/Q4Nh50MA4/VMjY6dBH4w7Fr5YdnlAjTjn7FPjO9+dHTff8oN45pnn44zm8+Ott1bFlM+dWHZpwEZcf/31sXz58vjUpz4Vw4YNW3/dfvvt3XofW/pJY8C2H4iIiDf+/EbJlQC1YF2liHVFEfV9endar+/TO371yrKSqgJqSd++fWO//faKyy6/Zv1aURQx5/55ccAB+5dYGfQc1Ty0ryu6uiPg/Sql4d/Q8wkrRSV61dlwwPtTV1cXp804LZ5a8Jv4P8/9tuxygBowoL5v7LXj9vHth56OEYO3je0H1Me9T70ST/7+v2OnQR8suzygBjQ2Doo+ffpEe1vnPzK2t78Wu33sIyVVBfQkXe6wV61aFfPmzYunn376Ha+9/fbbccstt2zyPTb0fMKXV7zU1VJgvTMvbY5dPrZLfLV508+5BOgul04aE1FEHHbVPfGJS38Ysxc8H4eP3Cl61ZVdGQAQEVFU8b+eqEsN/5IlS2L33XePgw8+OPbcc8845JBD4o9//OP615cvXx5TpkzZ5PtMnz49li9f3ukase2Hu149RETzJWfEAYeOiXM/c24sW2obLVA9Ow36YHz3c+Pj4fP/Lu6ddlTc+s8TYu26Inb4Gwk/sOUtW/Z6rF27NoY0NXZaHzJkcCxte62kqoCepEsN/3nnnRcjR46M9vb2eO6552LgwIExbty4+N3vftelm9bX18e2227b6bKdn/ej+ZIzYtzhn4wvfea8WPpKW9nlADWqf78+MXhg/1ixanXMf3FpfOpjw8suCagBa9asicWLn4xPjz9w/VpdXV18evyB8cgji0qsDHqOSlFU7eqJujTDP3/+/PjFL34RjY2N0djYGPfcc0+cccYZcdBBB8Uvf/nLGDBgwJaqE95h6qXNMf7Y8THjny+OVStXxXaDt4uIiJVvrIzVb68uuTqgFsx/YWkUUcQu2w+M373+Zlz1iydjROPAOHafLfMsXYC/dtU3b4ybvntVLFr8ZDz22K/irKmnxoAB/WPWzd170jewdepSw79q1aro0+f/f0tdXV1cf/31ceaZZ8YhhxwSs2fP7vYC4d0c/Y9HR0TEN+64otP6FS3fiPvuuK+MkoAa80bHmvjW/U9G24pV0dC/Xxy6+45x5viR0be3XWtAddxxx90xuHFQXHThF2Po0MHxxBO/iSOPOjna2405QkT00Mn66ulSw7/bbrvFwoULY/fdd++0fs01f3kUyDHHHNN9lcEmHLbT4WWXANS4iXvsFBP32KnsMoAad931s+K662eVXQbQA3UpgjjuuOPitttu2+Br11xzTXz2s5+t2vMEAQAAYGMqUVTt6om61PBPnz49fvazn73r69ddd11UKpXNLgoAAADYPF3a0g8AAABbi56avFeLU4UAAAAgIQk/AAAAKdX6GXMSfgAAAEhIwg8AAEBKZvgBAACAdCT8AAAApFRI+AEAAIBsNPwAAACQkC39AAAApOSxfAAAAEA6En4AAABS8lg+AAAAIB0JPwAAACmZ4QcAAADSkfADAACQkhl+AAAAIB0JPwAAACkVEn4AAAAgGwk/AAAAKVWc0g8AAABkI+EHAAAgJTP8AAAAQDoSfgAAAFIyww8AAACkI+EHAAAgJTP8AAAAQDoafgAAAEjIln4AAABScmgfAAAAkI6EHwAAgJQc2gcAAACkI+EHAAAgJTP8AAAAQDoSfgAAAFIyww8AAACkI+EHAAAgpaKolF1CqST8AAAAkJCEHwAAgJQqZvgBAACAbCT8AAAApFQUEn4AAAAgGQk/AAAAKZnhBwAAANKR8AMAAJCSGX4AAAAgHQk/AAAAKVUk/AAAAEA2Gn4AAABIyJZ+AAAAUio8lg8AAADIRsIPAABASh7LBwAAAKQj4QcAACClihl+AAAAIBsJPwAAACmZ4QcAAADSkfADAACQUkXCDwAAAGQj4QcAACAlM/wAAABAOhJ+AAAAUqqEhB8AAABIRsIPAABASmb4AQAAgHQk/AAAAKRUkfADAAAA2Wj4AQAAICFb+gEAAEip8Fg+AAAAIBsJPwAAACk5tA8AAABIR8IPAABASoWEHwAAAMhGwg8AAEBKTukHAAAA0pHwAwAAkJIZfgAAACAdDT8AAAApFUVRtev9uPbaa2OXXXaJbbbZJsaMGRMLFizo1p9fww8AAABVdvvtt0dLS0vMmDEjFi9eHHvvvXdMnDgx2tvbu+0eGn4AAABSKqp4ddWVV14Zp556akyZMiU+/vGPxw033BAf+MAH4nvf+977/GnfScMPAAAAm6mjoyNWrFjR6ero6Njg165evToWLVoUEyZMWL/Wq1evmDBhQjz88MPdVlOPOaX/P1+5t+wS2Ep1dHREa2trTJ8+Perr68suB6hBfg+xudaedEnZJbAV8zsI3t3a1a9W7V4XXXRRXHzxxZ3WZsyYERdddNE7vnbZsmWxbt26aGpq6rTe1NQUzz77bLfVVFfU+nMK2OqtWLEiGhoaYvny5bHtttuWXQ5Qg/weAsrkdxD0DB0dHe9I9Ovr6zf4h7g//OEPscMOO8T8+fNj7Nix69fPPffcePDBB+PRRx/tlpp6TMIPAAAAW6t3a+43pLGxMXr37h1tbW2d1tva2mLo0KHdVpMZfgAAAKiifv36xf777x9z5sxZv1apVGLOnDmdEv/NJeEHAACAKmtpaYnJkyfHqFGj4hOf+ETMnDkzVq5cGVOmTOm2e2j42erV19fHjBkzHFIDlMbvIaBMfgfB1ukzn/lMvPbaa3HhhRfG0qVLY5999ol77733HQf5bQ6H9gEAAEBCZvgBAAAgIQ0/AAAAJKThBwAAgIQ0/AAAAJCQhh8AAAAS0vCz1bv22mtjl112iW222SbGjBkTCxYsKLskoEbMnTs3jj766Bg+fHjU1dXFXXfdVXZJQA1pbW2N0aNHx8CBA2PIkCExadKkeO6558ouC+hBNPxs1W6//fZoaWmJGTNmxOLFi2PvvfeOiRMnRnt7e9mlATVg5cqVsffee8e1115bdilADXrwwQejubk5HnnkkbjvvvtizZo1cdhhh8XKlSvLLg3oIeqKoijKLgLerzFjxsTo0aPjmmuuiYiISqUSO+20U0ydOjXOP//8kqsDakldXV3ceeedMWnSpLJLAWrUa6+9FkOGDIkHH3wwDj744LLLAXoACT9brdWrV8eiRYtiwoQJ69d69eoVEyZMiIcffrjEygAAqm/58uURETFo0KCSKwF6Cg0/W61ly5bFunXroqmpqdN6U1NTLF26tKSqAACqr1KpxLRp02LcuHExcuTIsssBeog+ZRcAAABsnubm5njqqadi3rx5ZZcC9CAafrZajY2N0bt372hra+u03tbWFkOHDi2pKgCA6jrzzDPjJz/5ScydOzd23HHHsssBehBb+tlq9evXL/bff/+YM2fO+rVKpRJz5syJsWPHllgZAMCWVxRFnHnmmXHnnXfG/fffHyNGjCi7JKCHkfCzVWtpaYnJkyfHqFGj4hOf+ETMnDkzVq5cGVOmTCm7NKAGvPnmm/HCCy+s//fLL78cjz/+eAwaNCh23nnnEisDakFzc3PMnj07fvzjH8fAgQPXn2HU0NAQ/fv3L7k6oCfwWD62etdcc01cccUVsXTp0thnn33i6quvjjFjxpRdFlADHnjggRg/fvw71idPnhyzZs2qfkFATamrq9vg+k033RSf+9znqlsM0CNp+AEAACAhM/wAAACQkIYfAAAAEtLwAwAAQEIafgAAAEhIww8AAAAJafgBAAAgIQ0/AAAAJKThBwAAgIQ0/AAAAJCQhh8AAAAS0vADAABAQv8XxQQ94rIXJnYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1400x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating heatmap of confusion matrix \n",
    "import seaborn as sns\n",
    "plt.figure(figsize=[14,7])\n",
    "sns.heatmap(cm,annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "# creating the ann as sequence of layers\n",
    "\n",
    "ann = Sequential()\n",
    "\n",
    "#adding first hidden layer with 30 neurons,the input layer will be added automatically\n",
    "\n",
    "ann.add(Dense(units=30,activation='softmax'))\n",
    "ann.add(BatchNormalization())\n",
    "ann.add(Dropout(0.5))\n",
    "\n",
    "# adding output layer with 1 neuron, as this a binary classification\n",
    "\n",
    "ann.add(Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 89ms/step - loss: -22.3801 - accuracy: 0.6333 - val_loss: -22.9537 - val_accuracy: 0.6333\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: -22.3966 - accuracy: 0.6667 - val_loss: -23.1327 - val_accuracy: 0.6333\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: -21.3800 - accuracy: 0.6500 - val_loss: -23.3005 - val_accuracy: 0.6333\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: -20.8542 - accuracy: 0.6667 - val_loss: -23.4890 - val_accuracy: 0.6333\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: -21.9464 - accuracy: 0.6667 - val_loss: -23.6465 - val_accuracy: 0.6333\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: -18.8751 - accuracy: 0.5917 - val_loss: -23.9315 - val_accuracy: 0.6333\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: -21.3218 - accuracy: 0.6583 - val_loss: -24.1601 - val_accuracy: 0.6333\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: -22.2342 - accuracy: 0.6750 - val_loss: -24.3521 - val_accuracy: 0.6333\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: -22.6844 - accuracy: 0.6667 - val_loss: -24.4946 - val_accuracy: 0.6333\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: -22.6817 - accuracy: 0.6750 - val_loss: -24.6281 - val_accuracy: 0.6333\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: -23.1617 - accuracy: 0.6167 - val_loss: -24.8018 - val_accuracy: 0.6333\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: -22.3912 - accuracy: 0.5583 - val_loss: -25.0541 - val_accuracy: 0.6333\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: -23.8487 - accuracy: 0.6750 - val_loss: -25.2901 - val_accuracy: 0.6333\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: -23.5222 - accuracy: 0.6333 - val_loss: -25.4807 - val_accuracy: 0.6333\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: -23.3068 - accuracy: 0.6667 - val_loss: -25.6558 - val_accuracy: 0.6333\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: -23.6817 - accuracy: 0.6667 - val_loss: -25.8031 - val_accuracy: 0.6333\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: -24.0070 - accuracy: 0.6167 - val_loss: -26.0286 - val_accuracy: 0.6333\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: -22.9739 - accuracy: 0.6583 - val_loss: -26.2546 - val_accuracy: 0.6333\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: -22.1732 - accuracy: 0.6417 - val_loss: -26.4665 - val_accuracy: 0.6333\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: -24.3477 - accuracy: 0.6583 - val_loss: -26.6467 - val_accuracy: 0.6333\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: -24.8540 - accuracy: 0.6583 - val_loss: -26.8108 - val_accuracy: 0.6333\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: -24.5655 - accuracy: 0.6500 - val_loss: -26.9344 - val_accuracy: 0.6333\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: -24.4287 - accuracy: 0.5667 - val_loss: -27.1081 - val_accuracy: 0.6333\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: -23.8716 - accuracy: 0.6583 - val_loss: -27.3180 - val_accuracy: 0.6333\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: -24.4895 - accuracy: 0.6583 - val_loss: -27.5514 - val_accuracy: 0.6333\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: -24.3113 - accuracy: 0.5750 - val_loss: -27.8114 - val_accuracy: 0.6333\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: -26.0450 - accuracy: 0.6083 - val_loss: -28.0744 - val_accuracy: 0.6333\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -26.2052 - accuracy: 0.6250 - val_loss: -28.2794 - val_accuracy: 0.6333\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -26.3253 - accuracy: 0.5917 - val_loss: -28.4761 - val_accuracy: 0.6333\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -25.7649 - accuracy: 0.6667 - val_loss: -28.6365 - val_accuracy: 0.6333\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -25.3062 - accuracy: 0.6583 - val_loss: -28.7666 - val_accuracy: 0.6333\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -24.8349 - accuracy: 0.6250 - val_loss: -28.9040 - val_accuracy: 0.6333\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: -26.9210 - accuracy: 0.6500 - val_loss: -29.0479 - val_accuracy: 0.6333\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: -27.2288 - accuracy: 0.6417 - val_loss: -29.2273 - val_accuracy: 0.6333\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: -25.5017 - accuracy: 0.6333 - val_loss: -29.4669 - val_accuracy: 0.6333\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: -24.8241 - accuracy: 0.6667 - val_loss: -29.6837 - val_accuracy: 0.6333\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: -25.7680 - accuracy: 0.6417 - val_loss: -29.9194 - val_accuracy: 0.6333\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: -26.2682 - accuracy: 0.6583 - val_loss: -30.0936 - val_accuracy: 0.6333\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: -26.8726 - accuracy: 0.6667 - val_loss: -30.2418 - val_accuracy: 0.6333\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -28.3551 - accuracy: 0.6250 - val_loss: -30.4677 - val_accuracy: 0.6333\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -26.8416 - accuracy: 0.6250 - val_loss: -30.6718 - val_accuracy: 0.6333\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -27.2262 - accuracy: 0.6167 - val_loss: -30.8292 - val_accuracy: 0.6333\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -25.8862 - accuracy: 0.6417 - val_loss: -31.0001 - val_accuracy: 0.6333\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -26.3347 - accuracy: 0.5750 - val_loss: -31.2224 - val_accuracy: 0.6333\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -27.2956 - accuracy: 0.6500 - val_loss: -31.4640 - val_accuracy: 0.6333\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -27.4048 - accuracy: 0.6583 - val_loss: -31.6072 - val_accuracy: 0.6333\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -27.7718 - accuracy: 0.6417 - val_loss: -31.7074 - val_accuracy: 0.6333\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -27.9710 - accuracy: 0.6250 - val_loss: -31.8099 - val_accuracy: 0.6333\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -27.5462 - accuracy: 0.5833 - val_loss: -32.0595 - val_accuracy: 0.6333\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -27.7702 - accuracy: 0.6167 - val_loss: -32.3466 - val_accuracy: 0.6333\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -29.4229 - accuracy: 0.6583 - val_loss: -32.6571 - val_accuracy: 0.6333\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -28.4227 - accuracy: 0.6500 - val_loss: -32.8694 - val_accuracy: 0.6333\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -29.0594 - accuracy: 0.5750 - val_loss: -33.1631 - val_accuracy: 0.6333\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: -30.4144 - accuracy: 0.6417 - val_loss: -33.3375 - val_accuracy: 0.6333\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -29.5134 - accuracy: 0.6667 - val_loss: -33.5114 - val_accuracy: 0.6333\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -28.3529 - accuracy: 0.5417 - val_loss: -33.8567 - val_accuracy: 0.6333\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -27.3264 - accuracy: 0.6083 - val_loss: -34.0992 - val_accuracy: 0.6333\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -28.4751 - accuracy: 0.5333 - val_loss: -34.3527 - val_accuracy: 0.6333\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -31.8577 - accuracy: 0.6083 - val_loss: -34.6955 - val_accuracy: 0.6333\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -30.1116 - accuracy: 0.6583 - val_loss: -34.9474 - val_accuracy: 0.6333\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -29.7755 - accuracy: 0.6417 - val_loss: -35.0731 - val_accuracy: 0.6333\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -31.3138 - accuracy: 0.6417 - val_loss: -35.0985 - val_accuracy: 0.6333\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -29.0923 - accuracy: 0.6083 - val_loss: -35.2109 - val_accuracy: 0.6333\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -30.2146 - accuracy: 0.5417 - val_loss: -35.4383 - val_accuracy: 0.6333\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -31.6658 - accuracy: 0.6083 - val_loss: -35.6092 - val_accuracy: 0.6333\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -30.9499 - accuracy: 0.5917 - val_loss: -35.8464 - val_accuracy: 0.6333\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -30.2419 - accuracy: 0.6083 - val_loss: -36.0959 - val_accuracy: 0.6333\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -32.4728 - accuracy: 0.6167 - val_loss: -36.4014 - val_accuracy: 0.6333\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -30.2737 - accuracy: 0.5250 - val_loss: -36.7154 - val_accuracy: 0.6333\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -31.3278 - accuracy: 0.5667 - val_loss: -36.8991 - val_accuracy: 0.6333\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -31.9843 - accuracy: 0.6000 - val_loss: -37.1684 - val_accuracy: 0.6333\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -30.9107 - accuracy: 0.6583 - val_loss: -37.3094 - val_accuracy: 0.6333\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -33.3312 - accuracy: 0.5917 - val_loss: -37.4186 - val_accuracy: 0.6333\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -32.8664 - accuracy: 0.6250 - val_loss: -37.4882 - val_accuracy: 0.6333\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -30.2052 - accuracy: 0.5917 - val_loss: -37.6277 - val_accuracy: 0.6333\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -32.9703 - accuracy: 0.6417 - val_loss: -37.8387 - val_accuracy: 0.6333\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -31.7119 - accuracy: 0.6250 - val_loss: -37.9711 - val_accuracy: 0.6333\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -32.0183 - accuracy: 0.6083 - val_loss: -38.0838 - val_accuracy: 0.6333\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -34.8819 - accuracy: 0.5917 - val_loss: -38.2873 - val_accuracy: 0.6333\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -33.1064 - accuracy: 0.5750 - val_loss: -38.5403 - val_accuracy: 0.6333\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -34.4829 - accuracy: 0.6000 - val_loss: -38.8783 - val_accuracy: 0.6333\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -35.0938 - accuracy: 0.6333 - val_loss: -39.1299 - val_accuracy: 0.6333\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -32.5584 - accuracy: 0.5667 - val_loss: -39.3228 - val_accuracy: 0.6333\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: -30.9664 - accuracy: 0.5333 - val_loss: -39.5885 - val_accuracy: 0.6333\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -35.2984 - accuracy: 0.6083 - val_loss: -39.9075 - val_accuracy: 0.6333\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -33.6683 - accuracy: 0.6250 - val_loss: -40.1242 - val_accuracy: 0.6333\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -35.0307 - accuracy: 0.6250 - val_loss: -40.3355 - val_accuracy: 0.6333\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -34.7240 - accuracy: 0.5833 - val_loss: -40.5069 - val_accuracy: 0.6333\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -36.1612 - accuracy: 0.5583 - val_loss: -40.6831 - val_accuracy: 0.6333\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -34.4729 - accuracy: 0.6250 - val_loss: -40.8643 - val_accuracy: 0.6333\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: -32.6195 - accuracy: 0.5833 - val_loss: -41.0468 - val_accuracy: 0.6333\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -34.4676 - accuracy: 0.6083 - val_loss: -41.2725 - val_accuracy: 0.6333\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -36.2980 - accuracy: 0.6250 - val_loss: -41.5244 - val_accuracy: 0.6333\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -35.1141 - accuracy: 0.6167 - val_loss: -41.6813 - val_accuracy: 0.6333\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -37.6199 - accuracy: 0.6167 - val_loss: -41.8348 - val_accuracy: 0.6333\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: -37.3450 - accuracy: 0.6417 - val_loss: -42.0173 - val_accuracy: 0.6333\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: -34.7593 - accuracy: 0.6250 - val_loss: -42.2133 - val_accuracy: 0.6333\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -36.8481 - accuracy: 0.6333 - val_loss: -42.3585 - val_accuracy: 0.6333\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -35.0311 - accuracy: 0.5667 - val_loss: -42.6467 - val_accuracy: 0.6333\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -37.6663 - accuracy: 0.6000 - val_loss: -42.8721 - val_accuracy: 0.6333\n"
     ]
    }
   ],
   "source": [
    "#compiling the ann using stochastic gradient descent (optimizer - adam)\n",
    "\n",
    "ann.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#setting callback for monitoring maximum accuracy\n",
    "\n",
    "from tabnanny import verbose\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',mode = 'min',verbose=1,patience=25)\n",
    "\n",
    "#training the ann with batch size of 32 (this is a batch learning)\n",
    "\n",
    "model = ann.fit(x_train,y_train,batch_size=32,validation_data=(x_test,y_test),epochs=100,callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPILING THE ANN USING STOCHASTIC GRADIENT DESENT(optimizer = 'adam')\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#SETTING CALLBACKS FOR MONITERING MAXIMUM ACCURACY\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 56ms/step - loss: -36.2671 - accuracy: 0.6000 - val_loss: -43.3580 - val_accuracy: 0.6333\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -38.9427 - accuracy: 0.5333 - val_loss: -43.3991 - val_accuracy: 0.6333\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: -37.1145 - accuracy: 0.5833 - val_loss: -43.6016 - val_accuracy: 0.6333\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -37.4009 - accuracy: 0.6250 - val_loss: -43.8418 - val_accuracy: 0.6333\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -37.8797 - accuracy: 0.5667 - val_loss: -44.1076 - val_accuracy: 0.6333\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: -41.0771 - accuracy: 0.6083 - val_loss: -44.2889 - val_accuracy: 0.6333\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -37.4311 - accuracy: 0.6000 - val_loss: -44.3829 - val_accuracy: 0.6333\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: -39.1733 - accuracy: 0.5750 - val_loss: -44.5091 - val_accuracy: 0.6333\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: -37.5654 - accuracy: 0.5917 - val_loss: -44.5892 - val_accuracy: 0.6333\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -39.5736 - accuracy: 0.5167 - val_loss: -44.7784 - val_accuracy: 0.6333\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -41.1241 - accuracy: 0.6083 - val_loss: -45.0065 - val_accuracy: 0.6333\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: -39.3313 - accuracy: 0.6417 - val_loss: -45.1478 - val_accuracy: 0.6333\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -39.8223 - accuracy: 0.6333 - val_loss: -45.3102 - val_accuracy: 0.6333\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -40.4224 - accuracy: 0.5917 - val_loss: -45.4244 - val_accuracy: 0.6333\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: -41.2556 - accuracy: 0.6250 - val_loss: -45.6597 - val_accuracy: 0.6333\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -40.2739 - accuracy: 0.6167 - val_loss: -45.8591 - val_accuracy: 0.6333\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -40.9540 - accuracy: 0.6250 - val_loss: -45.9848 - val_accuracy: 0.6333\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -38.8598 - accuracy: 0.6083 - val_loss: -46.1659 - val_accuracy: 0.6333\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -40.6357 - accuracy: 0.6500 - val_loss: -46.4223 - val_accuracy: 0.6333\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -42.1836 - accuracy: 0.6167 - val_loss: -46.6253 - val_accuracy: 0.6333\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -41.7658 - accuracy: 0.6250 - val_loss: -46.7806 - val_accuracy: 0.6333\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -41.8138 - accuracy: 0.6500 - val_loss: -46.9407 - val_accuracy: 0.6333\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -41.6153 - accuracy: 0.6250 - val_loss: -47.1348 - val_accuracy: 0.6333\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -40.6673 - accuracy: 0.5750 - val_loss: -47.4016 - val_accuracy: 0.6333\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -41.9086 - accuracy: 0.5833 - val_loss: -47.7312 - val_accuracy: 0.6333\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -39.9034 - accuracy: 0.5833 - val_loss: -48.0841 - val_accuracy: 0.6333\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -44.6062 - accuracy: 0.5917 - val_loss: -48.5037 - val_accuracy: 0.6333\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -42.8036 - accuracy: 0.4917 - val_loss: -48.9296 - val_accuracy: 0.6333\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -42.6555 - accuracy: 0.6000 - val_loss: -49.2935 - val_accuracy: 0.6333\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -44.0948 - accuracy: 0.5750 - val_loss: -49.5298 - val_accuracy: 0.6333\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -42.7641 - accuracy: 0.5833 - val_loss: -49.8591 - val_accuracy: 0.6333\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -40.4825 - accuracy: 0.5833 - val_loss: -50.1741 - val_accuracy: 0.6333\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -44.4570 - accuracy: 0.5333 - val_loss: -50.5653 - val_accuracy: 0.6333\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -44.6919 - accuracy: 0.6167 - val_loss: -50.8556 - val_accuracy: 0.6333\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -44.4643 - accuracy: 0.5500 - val_loss: -51.1051 - val_accuracy: 0.6333\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -42.1230 - accuracy: 0.5750 - val_loss: -51.2157 - val_accuracy: 0.6333\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -44.7500 - accuracy: 0.6000 - val_loss: -51.2606 - val_accuracy: 0.6333\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -45.4817 - accuracy: 0.5500 - val_loss: -51.2581 - val_accuracy: 0.6333\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: -46.7464 - accuracy: 0.6083 - val_loss: -51.2499 - val_accuracy: 0.6333\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -44.8070 - accuracy: 0.5250 - val_loss: -51.4071 - val_accuracy: 0.6333\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -41.3212 - accuracy: 0.5083 - val_loss: -51.5654 - val_accuracy: 0.6333\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -43.0305 - accuracy: 0.5833 - val_loss: -51.8488 - val_accuracy: 0.6333\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -42.6816 - accuracy: 0.5833 - val_loss: -52.2171 - val_accuracy: 0.6333\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -46.3617 - accuracy: 0.5917 - val_loss: -52.5208 - val_accuracy: 0.6333\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -45.1898 - accuracy: 0.5667 - val_loss: -52.7681 - val_accuracy: 0.6333\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -46.1078 - accuracy: 0.6333 - val_loss: -52.9548 - val_accuracy: 0.6333\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -44.6530 - accuracy: 0.6167 - val_loss: -53.0665 - val_accuracy: 0.6333\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -46.8524 - accuracy: 0.6583 - val_loss: -53.0987 - val_accuracy: 0.6333\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -44.8287 - accuracy: 0.6000 - val_loss: -53.1819 - val_accuracy: 0.6333\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -48.9195 - accuracy: 0.6083 - val_loss: -53.2365 - val_accuracy: 0.6333\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -48.2149 - accuracy: 0.5750 - val_loss: -53.4069 - val_accuracy: 0.6333\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -48.6611 - accuracy: 0.5333 - val_loss: -53.7031 - val_accuracy: 0.6333\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: -48.4311 - accuracy: 0.5833 - val_loss: -54.0294 - val_accuracy: 0.6333\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: -48.8445 - accuracy: 0.5833 - val_loss: -54.2602 - val_accuracy: 0.6333\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: -48.0381 - accuracy: 0.5500 - val_loss: -54.6666 - val_accuracy: 0.6333\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: -48.4173 - accuracy: 0.5833 - val_loss: -54.9246 - val_accuracy: 0.6333\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: -43.3301 - accuracy: 0.5083 - val_loss: -55.3192 - val_accuracy: 0.6333\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: -44.1239 - accuracy: 0.5167 - val_loss: -55.6945 - val_accuracy: 0.6333\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: -46.3538 - accuracy: 0.6083 - val_loss: -56.0683 - val_accuracy: 0.6333\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -47.5561 - accuracy: 0.5583 - val_loss: -56.3481 - val_accuracy: 0.6333\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -47.0948 - accuracy: 0.5333 - val_loss: -56.5609 - val_accuracy: 0.6333\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -51.9274 - accuracy: 0.5750 - val_loss: -56.8745 - val_accuracy: 0.6333\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -50.0493 - accuracy: 0.6417 - val_loss: -57.1011 - val_accuracy: 0.6333\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -50.5099 - accuracy: 0.5917 - val_loss: -57.2005 - val_accuracy: 0.6333\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: -49.1554 - accuracy: 0.5500 - val_loss: -57.2969 - val_accuracy: 0.6333\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: -49.1461 - accuracy: 0.5667 - val_loss: -57.4736 - val_accuracy: 0.6333\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: -49.3527 - accuracy: 0.6083 - val_loss: -57.5997 - val_accuracy: 0.6333\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: -54.0763 - accuracy: 0.6000 - val_loss: -57.7350 - val_accuracy: 0.6333\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: -50.5938 - accuracy: 0.5667 - val_loss: -57.8745 - val_accuracy: 0.6333\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: -49.5307 - accuracy: 0.5500 - val_loss: -58.0296 - val_accuracy: 0.6333\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -49.6766 - accuracy: 0.6000 - val_loss: -58.1878 - val_accuracy: 0.6333\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: -49.1008 - accuracy: 0.5750 - val_loss: -58.4853 - val_accuracy: 0.6333\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -53.2113 - accuracy: 0.6000 - val_loss: -58.7534 - val_accuracy: 0.6333\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: -49.5692 - accuracy: 0.6083 - val_loss: -58.8715 - val_accuracy: 0.6333\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: -55.3930 - accuracy: 0.5917 - val_loss: -59.0914 - val_accuracy: 0.6333\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: -51.4136 - accuracy: 0.6417 - val_loss: -59.2177 - val_accuracy: 0.6333\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -51.8268 - accuracy: 0.5917 - val_loss: -59.3326 - val_accuracy: 0.6333\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: -52.1052 - accuracy: 0.6083 - val_loss: -59.4571 - val_accuracy: 0.6333\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: -52.8787 - accuracy: 0.5417 - val_loss: -59.5890 - val_accuracy: 0.6333\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: -54.4441 - accuracy: 0.5917 - val_loss: -59.9386 - val_accuracy: 0.6333\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: -49.7805 - accuracy: 0.5000 - val_loss: -60.4802 - val_accuracy: 0.6333\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: -53.8249 - accuracy: 0.5250 - val_loss: -61.0896 - val_accuracy: 0.6333\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: -56.4469 - accuracy: 0.6250 - val_loss: -61.4748 - val_accuracy: 0.6333\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -52.6707 - accuracy: 0.5583 - val_loss: -61.8601 - val_accuracy: 0.6333\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -51.7429 - accuracy: 0.5917 - val_loss: -62.1119 - val_accuracy: 0.6333\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: -52.4255 - accuracy: 0.4917 - val_loss: -62.5240 - val_accuracy: 0.6333\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -52.0067 - accuracy: 0.5917 - val_loss: -62.8339 - val_accuracy: 0.6333\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: -53.8877 - accuracy: 0.5833 - val_loss: -63.1465 - val_accuracy: 0.6333\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: -54.5418 - accuracy: 0.5833 - val_loss: -63.3130 - val_accuracy: 0.6333\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -49.7324 - accuracy: 0.4500 - val_loss: -63.8471 - val_accuracy: 0.6333\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -56.2528 - accuracy: 0.5667 - val_loss: -64.1664 - val_accuracy: 0.6333\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -57.4088 - accuracy: 0.5917 - val_loss: -64.4230 - val_accuracy: 0.6333\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -56.3082 - accuracy: 0.6000 - val_loss: -64.4913 - val_accuracy: 0.6333\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -53.4601 - accuracy: 0.6000 - val_loss: -64.5218 - val_accuracy: 0.6333\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -58.5193 - accuracy: 0.6083 - val_loss: -64.5228 - val_accuracy: 0.6333\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -54.6173 - accuracy: 0.5750 - val_loss: -64.5678 - val_accuracy: 0.6333\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -57.7904 - accuracy: 0.5000 - val_loss: -64.7318 - val_accuracy: 0.6333\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -61.8035 - accuracy: 0.5917 - val_loss: -64.9643 - val_accuracy: 0.6333\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -55.1730 - accuracy: 0.6083 - val_loss: -65.1554 - val_accuracy: 0.6333\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -51.5723 - accuracy: 0.4917 - val_loss: -65.5146 - val_accuracy: 0.6333\n"
     ]
    }
   ],
   "source": [
    "#TRAINING THE ANN WITH BATCH SIZE OF 32 (THIS IS A BATCH LEARNING)\n",
    "from keras import callbacks\n",
    "\n",
    "\n",
    "model=ann.fit(x_train,y_train,batch_size = 32, validation_data=(x_test,y_test),epochs =100,callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01fe06809b6d42a5731ad1e6710c0526d53fcbfb34f2a5ab4ffc106106c8aff0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
